{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec387931",
   "metadata": {},
   "source": [
    "\n",
    "# Question 1\n",
    "\n",
    "### Summary of Interaction\n",
    "\n",
    "In our interaction, you requested assistance in finding an interesting dataset with missing values available online. I provided you with the Titanic dataset, which is well-known for its mix of categorical and numerical data, and includes missing values. You then asked for help loading the dataset into a Jupyter notebook using pandas and obtaining the missing data counts. I provided you with the necessary code to achieve this.\n",
    "\n",
    "### Final Working Version of the Code\n",
    "\n",
    "Here is the final version of the code to load the Titanic dataset and get the missing data counts:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the count of missing values for each column\n",
    "missing_data_counts = df.isnull().sum()\n",
    "\n",
    "print(missing_data_counts)\n",
    "```\n",
    "\n",
    "This code will load the Titanic dataset from the provided URL and print out the number of missing values in each column. Yes, the Titanic dataset does have missing values. Specifically, it includes missing values in columns such as Age and Embarked12. The code you have will correctly identify and count these missing values for each column.\n",
    "\n",
    "\n",
    "\n",
    "If you need any further assistance or have additional questions, feel free to ask! Good luck with your assignment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616c7de",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "1. \n",
    "\n",
    "Certainly! Here's a summary of our exchanges:\n",
    "\n",
    "    1. You downloaded the **Titanic dataset** from [this link](https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv). The dataset contains **418 rows** and **13 columns**.\n",
    "    2. You asked for an explanation of the terms \"observations\" and \"variables\" in the context of your dataset. I provided definitions for both:\n",
    "       - Observations (Rows): Individual instances or data points (e.g., passengers on the Titanic).\n",
    "       - Variables (Columns): Different characteristics or features associated with each observation (e.g., age, sex, ticket class, fare, survival status).\n",
    "    3. You requested a summary for your homework assignment.\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "2. \n",
    "\n",
    "    Observation - An observationis defined as the invidual instances (or data points)of a data set, in the example of the titanic it is the rows and it contains one individual, and the columns(Variables), which represents the characteristics associated with this indivdual passenger. \n",
    "\n",
    "    Variable - A variable is the different characteristics associated with each individual instance (observation). In the context of the titanic, some examples may be a passenger's sex, ticket, classs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236d3711",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Sure, here's a summary of our interactions and the final version of the code we created together:\n",
    "\n",
    "### Summary of Our Interactions\n",
    "\n",
    "1. **Initial Request**: You asked for help with loading a dataset from a URL using pandas and checking for missing values in each column.\n",
    "2. **Code Provided**: I provided you with code to load the dataset and count the missing values for each column.\n",
    "3. **Further Request**: You asked how to provide simple summaries of the columns in the dataset using `df.describe()` and `df['column'].value_counts()`.\n",
    "4. **Code Provided**: I provided you with code to get a summary of the numerical columns using `df.describe()` and to get the count of unique values for specific categorical columns using `df['column'].value_counts()`.\n",
    "\n",
    "### Final Working Version of the Code\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the count of missing values for each column\n",
    "missing_data_counts = df.isnull().sum()\n",
    "print(\"Missing values for each column:\\n\", missing_data_counts)\n",
    "\n",
    "# Get a summary of the numerical columns\n",
    "numerical_summary = df.describe()\n",
    "print(\"\\nSummary of numerical columns:\\n\", numerical_summary)\n",
    "\n",
    "# Get the count of unique values for a specific column, e.g., 'sex'\n",
    "value_counts_sex = df['sex'].value_counts()\n",
    "print(\"\\nValue counts for 'sex' column:\\n\", value_counts_sex)\n",
    "\n",
    "# You can do the same for other categorical columns, e.g., 'embarked'\n",
    "value_counts_embarked = df['embarked'].value_counts()\n",
    "print(\"\\nValue counts for 'embarked' column:\\n\", value_counts_embarked)\n",
    "```\n",
    "\n",
    "Feel free to use this summary and code for your homework assignment. If you need any more help, just let me know!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a401f7",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Discrepancies Explained\n",
    "\n",
    "    (a) Number of Columns Analyzed\n",
    "    Non-numeric Variables: By default, df.describe() only analyzes numeric columns. If your dataset has non-numeric columns (e.g., strings or categorical data), these columns will not be included in the summary statistics unless you explicitly include them using df.describe(include='all').\n",
    "    Example: If your dataset has 12 columns but only 8 are numeric, df.describe() will only provide summaries for those 8 numeric columns.\n",
    "    \n",
    "    \n",
    "    (b) Values Reported in the “Count” Column\n",
    "    Missing Values in Numeric Variables: The “count” column in df.describe() shows the number of non-missing (non-NaN) values for each numeric column.\n",
    "    Discrepancy: If there are missing values in numeric columns, the “count” reported by df.describe() will be less than the total number of rows in the dataset.\n",
    "    Example: If a numeric column has 891 rows but 10 missing values, df.describe() will report the count as 881 for that column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dba768",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "Attribute is defined as a characteristic of an object, it does not require parenthese becauses its an attribute. Furthermore, it holds some data or state related to the object. For example, df.shape is an attribute and it provides information - rows and columns - about the dataframe. It returns a tuple in the form of (rows, columns)\n",
    "\n",
    "Method is defined as a function that is associated with an object. It performs operations and requires a parentheses. For example, since df.describe() has an parentheses behind it, it is a method. It performs calulation operation on dataframe, and generates summary of simple statistical summary. \n",
    "\n",
    "Therefore, the key difference between attributes and methods is that the former doesn't require parentheses while the ladder requires parenthesis. The purpose also differs, as attribute provides data or state information about the object. The method performs actions or operations on the object. Lastly, their output differs too, as attributes often produces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4746f901",
   "metadata": {},
   "source": [
    "#  Question 6\n",
    "Definition of:\n",
    "\n",
    "    - count it is the non missing values in each column. It identify how many valid data points are represented at each variable. \n",
    "    \n",
    "    - mean - It is the average value of data in each column, which is calculated by dividing the sum of all values dividing by the count of values. It provides a centeral value for the data. \n",
    "    \n",
    "    - std - STD is the abbreivation for standard deviation In other words, it measures the dispersion in the data or how spread out the values are around the mean. \n",
    "    \n",
    "    - min - The smallest numerical value, which is also the lower bound of the data. \n",
    "    \n",
    "    - 25% This is the value below which 25% of the data falls, and is also known as Q1. \n",
    "    \n",
    "    - 50% This is the middle value of the data, also known as the median. \n",
    "    \n",
    "    -75% This is the value below which 75% of the data falls, known as Q3. \n",
    "    \n",
    "    -max This is the largest numerical value in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c5dd395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "     A    B    C\n",
      "0  1.0  NaN  1.0\n",
      "1  2.0  2.0  NaN\n",
      "2  NaN  3.0  3.0\n",
      "3  4.0  NaN  4.0\n",
      "4  5.0  5.0  NaN\n",
      "\n",
      "Missing values in each column:\n",
      "A    1\n",
      "B    2\n",
      "C    2\n",
      "dtype: int64\n",
      "\n",
      "After deleting column 'B':\n",
      "     A    C\n",
      "0  1.0  1.0\n",
      "1  2.0  NaN\n",
      "2  NaN  3.0\n",
      "3  4.0  4.0\n",
      "4  5.0  NaN\n",
      "\n",
      "After dropping rows with missing values:\n",
      "     A    C\n",
      "0  1.0  1.0\n",
      "3  4.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Question 7\n",
    "\n",
    "#1. Use case for df.dropna()\n",
    "\n",
    "#This is useful where you have columns of valuable data, but some rows contains missing values. If you want to retain as many rows as possible while allowing some rows with missing data to be deleted, this is the appropiate method. In this scenario, it is more efficient to drop rows with missing data using df.dropna() rather than removing entire columns since only a few are affected. \n",
    "\n",
    "#2. Use case for del df['col']\n",
    "\n",
    "#When there is a colum that contains a large amount of missing data, keeping the column would introduce too much missing data, therefore, del df['col] is used to remove those columns of data that is not critical to your analysis. \n",
    "\n",
    "#3. Why applying del df['col'] before df.dropna() is important\n",
    "\n",
    "#It improves the effiency as if the columns with a high percentage of missing data is deleted first, more rows will be reserved because if you don't, df.dropna() might remove rows that only have missing values in non-critical columns, unnecessarily reducing the size of your dataset. \n",
    "\n",
    "#4. Remove missing data\n",
    "\n",
    "#I used the help of chatbot to answer this question. This is the original dataset with missing values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'A': [1, 2, None, 4, 5],\n",
    "    'B': [None, 2, 3, None, 5],\n",
    "    'C': [1, None, 3, 4, None]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Before:\")\n",
    "print(df)\n",
    "\n",
    "##Afterwards, it uses a df.isnull().sum() to identify the number of missing values in each column. \n",
    "\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "##Remove missing data using df.dropna(). \n",
    "\n",
    "# Delete column 'B' because it has too many missing values\n",
    "del df['B']\n",
    "print(\"\\nAfter deleting column 'B':\")\n",
    "print(df)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "print(\"\\nAfter dropping rows with missing values:\")\n",
    "print(df_cleaned)\n",
    "\n",
    "##Deleting Columns: This is useful when a column has a high percentage of missing values, making it less informative or reliable. \n",
    "\n",
    "##Dropping Rows: This is effective when the dataset is large enough that losing some rows won't significantly impact the analysis. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4905e247",
   "metadata": {},
   "source": [
    "# Question 8.1 - 8.2\n",
    "\n",
    "1. \n",
    "\n",
    "Firstly, I'm going to describe what df.groupby(\"col1\")[\"col2\"].describe does in a panada DataFrame. The method df.groupby(\"col1\" groups the dataframe df by the values in colum \"col1\". Each unique value in col1 will form as a seperate group. [\"col2\"] Occurs after grouping by col1. The method.desribe() is used to describe summary statistics of col2 within each group. \n",
    "\n",
    "Originally if I have a data set composed of two columns 'col1' and 'col2'. \n",
    " 'col1': ['A', 'A', 'B', 'B', 'B', 'C', 'C'],\n",
    " 'col2': [10, 20, 30, 40, 50, 60, 70]\n",
    " \n",
    " If i used the function df.groupby(\"col1\")[\"col2].describe() then the summary statistics of each group, in this case A,B,C will be outputed. For example, it would have the data for A's  count, mean, std, min, 25%,50%,75% and max.  \n",
    " \n",
    " \n",
    "\n",
    "2. \n",
    "\n",
    "The count values in df.describe() and df.groupby(\"col1\")[\"col2].describe() provides a group wise summary, whereas df.describe() provides column wise summary across the entire dataframe. Therefore, the count values in the two different functions capture fundamentally different aspects of the data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce676b",
   "metadata": {},
   "source": [
    "# Question 8.3 - A\n",
    " [https://chatgpt.com/share/66ef16ac-e520-8001-b0b6-d708ce5b487e]\n",
    " \n",
    "Question A\n",
    "\n",
    "\n",
    "Load the dataset\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "Get the count of missing values for each column\n",
    "missing_data_counts = df.isnull().sum()\n",
    "\n",
    "print(missing_data_counts)\n",
    "\n",
    "CHATGPT- The error `NameError: name 'pd' is not defined` usually occurs because the `pandas` library hasn't been imported as `pd`. You need to import the pandas library at the beginning of your code. You can do this by adding the following line at the top of your script: import pandas as pdThis imports pandas and assigns it the alias `pd`, which is a common convention. Let me know if that resolves the issue!\n",
    "\n",
    "My opinion: In this scenario, I find that it is faster to use chatGPT because it provides and clear and direct explanation to what the problem is and how to fix it. Whereas for google I had to go on a website called stack overflow to learn the meaning of this trouble shooting message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf5c3ba",
   "metadata": {},
   "source": [
    "# Question 8.3 - B\n",
    "\n",
    "[https://chatgpt.com/share/66ef16ac-e520-8001-b0b6-d708ce5b487e]\n",
    "\n",
    "Question B\n",
    "\n",
    "CHATGPT - The `FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv'` error occurs when the code is trying to access a file that doesn't exist at the specified location. To fix this error, you can:\n",
    "\n",
    "1. **Check the file name:** Ensure that the file is correctly named and matches exactly with `'titanics.csv'`. File names are case-sensitive and must include the correct extension (e.g., `.csv`).\n",
    "\n",
    "2. **Check the file path:** If the file is not in the same directory as your script, you'll need to specify the full or relative path to the file. For example:\n",
    "   ```python\n",
    "   df = pd.read_csv('path/to/your/titanics.csv')\n",
    "   ```\n",
    "   Replace `'path/to/your/titanics.csv'` with the correct path to the file.\n",
    "\n",
    "3. **Ensure the file exists:** Double-check that the file exists on your system at the given location.\n",
    "\n",
    "4. **Use the correct working directory:** If you're running the script from a specific environment (like Jupyter Notebook or an IDE), make sure the working directory is set to the folder containing the file.\n",
    "\n",
    "If you're still having trouble, let me know where the file is located, and I can help you adjust the file path accordingly.\n",
    "\n",
    "My opinion: In this case, I find that chatGPT is still the better alternative as it gives the better explanation, not only so, it gives you a step by step instructions on how to check for the error and how to fix it. Whereas google tells you what the problem is, but you have to dig deeper to find out how to fix it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9703a741",
   "metadata": {},
   "source": [
    "# Question 8.3 - C\n",
    "\n",
    "Question C\n",
    "\n",
    "In this case, I encountered an error message called NameError. After a quick google search, this error message occurs when you try o use a dataframe before it has been assigned to a variable. The solution to this is assign a variable first before you use the data frame.\n",
    "\n",
    "My Opinion: In this case, google serves as the better option because chatGPT gave too many necessary advice and comments, google in this case is the more efficent method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b54e9d",
   "metadata": {},
   "source": [
    "# Question 8.3 - D\n",
    "\n",
    "The error message I encountered when I didn't type one of the parenthesis is called Syntax error. For specifically,it is Syntax Error: Unexpected EOF while parsing. This error is encountered because Python expects the parentheses to be closed but reach the end of the file without finding it. \n",
    "\n",
    "My opinion: I find that using chatGPT in this scenario is more efficient, because it can pinpoint the problem and explain it in a very clear and direct manner which Whereas for google I had to go on a website called stack overflow to learn the meaning of this trouble shooting message. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee5fd6f",
   "metadata": {},
   "source": [
    "# Question 8.3 - E\n",
    "\n",
    "Question E \n",
    "\n",
    "The error message I encountered from df.group_by(\"col1\")[\"col2\"].describe() instead of df.groupby(\"col1\")[\"col2\"].describe() is an AttributeERROR. This occurs because it is not a valid method, and that was a typo or it is not a valid method for a pandas dataframe (correct method is groupby). To correct this error, I input my code into chatGPT and it was a quick fix, such as adding parentheses or correcting my code to use the correct method such as groupby. \n",
    "\n",
    "My opinion: Again, I find chatGPT to be much more efficient than a google serch as it offers a clear, direct, straightforward trouble shooting methods compared to google. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c4c1b",
   "metadata": {},
   "source": [
    "# Question 8.3 - F\n",
    "\n",
    "Question F\n",
    "\n",
    "The error message I encountered is KeyERROR, this is a result of using a column name that is not in my DataFRAME. Captialization is important in ensuring the correct column name is used. \n",
    "\n",
    "In this case, I find that chatGPT is still the better alternative as it gives the better explanation, not only so, it gives you a step by step instructions on how to check for the error and how to fix it. Whereas google tells you what the problem is, but you have to dig deeper to find out how to fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828ecaf",
   "metadata": {},
   "source": [
    "# Question 8.3 - G \n",
    "The error message I encountered is NameError: name 'sex' is not defined'. The fix is to enclosed age in quotes, or else Python would try to interpret it as a variable instead of string. \n",
    "\n",
    "My opinion: I find that using chatGPT in this scenario is more efficient, because it can pinpoint the problem and explain it in a very clear and direct manner which google searches takes a lot more time to understand the problem compared to chatGPT. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c7addb",
   "metadata": {},
   "source": [
    "# Question 9\n",
    "\n",
    "Yes I have indeed reviewed the course textbook. I find the instructions quiet confusing at first but figured out how to solve it when looking at Piazza."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
