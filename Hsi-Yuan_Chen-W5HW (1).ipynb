{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa046f7",
   "metadata": {},
   "source": [
    "# Question 1 \n",
    "[ChatBot : \"https://chatgpt.com/share/670f3c73-3998-8001-bcf1-94f002de4b45\"]\n",
    "\n",
    "\n",
    "\n",
    "What is the key factor that makes the difference between ideas that can, and cannot be examined and tested statistically?\n",
    "- Measurability, the data has to be quantified or observed in aconsistent manner.Observable data, there must be data or information that can collect through observation, experiments...etc. Falsifiability, there should be a way where it is possible to prove it false. Lastly, data should be gathered and anlyzed in repeatable manner. \n",
    "\n",
    "\n",
    "What would you describe is the key \"criteria\" defining what a good null hypothesis is? \n",
    "- Clarity, the null hypothesis should be clear and precise so that it can be easily understood and interpreted. Furthermore, it should be testable using available data and statistical methods. It should also be framed in a way that allows it to be proven false. \n",
    "\n",
    "And what is the difference between a null hypothesis and an alternative hypothesis in the context of hypothesis testing? \n",
    "- The null hypothesis is the default assumption that there is no effect, no difference, or no relationship. The alternative hypothesis is the statement that contradicts the null hypothesis. A low p-value, provide strong evidence to reject the null hypothesis. When the null hypothesis, then the alternative hypothesis is considered to be supported by the data. \n",
    "\n",
    "\n",
    "Null Hypothesis: Default assumption that there is no effect or no difference. \n",
    "Alternative Hypothesis: There is an effect or a difference. \n",
    "P-Value:\n",
    "- Helps you determine the significance of your results when conducting a hypothesis test. A small p-value indicates strong evidence against the null hypothesis (<= 0.05), a large p-value (>0.05), weak evident against the null hypothesis (accpeting the alternative hypothesis). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4692b75",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "-Population Parameter(μ): True average or characteristic for an entire population, such was the average height of all adults in a country. We usually don't know the exact value μ, so we estimate. \n",
    "\n",
    "-Sample Statistic(x̄): This is the average or characteristic calculated from a sample taken from the population. \n",
    "\n",
    "-Indivudal Data Points (xᵢ), represent individual values within a sample or population. \n",
    "\n",
    "-Hypothesized Parameter (μ₀): Specific value of μ₀ that we assume for testing purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7296cc4d",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "When we calculate p-value, we start by assuming the null hypothesis is true. This means we imagine a scenario where there's no effect, no difference, or no relationship between the variables we're studying. If the data we observe is very unlikely under this \"null hypothesis world\" it suggests that our assumption may not be accurate. Vice versa is true. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6003460c",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "When the p-value is very small, it indicates that the chance of observing our data under the null hypothesis is low. In other words, if the null hypothesis were really true, it would be pretty suprising to get the results we did. So, a tiny p-value makes the null hypothesis seem less believable (or “ridiculous”) because it suggests that the data we observed doesn’t align well with a world where there’s no effect or difference. Instead, it points us toward the alternative hypothesis—the idea that something is actually happening—and makes it more reasonable to believe that the null hypothesis might be wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9fbd27",
   "metadata": {},
   "source": [
    "# Question 5 \n",
    "\n",
    "Null hypothesis: expect probability of couples tilting their heads to the right should be 0.5. μ = μ₀ = 0.5\n",
    "\n",
    "xᵢ: Each individual couple's head tilt direction (right or left).\n",
    "x̄: The observed proportion of couples tilting their heads to the right, which is 64.5% or 0.645.\n",
    "μ: The true proportion of couples in the population who tilt their heads to the right. This is what we want to infer about based on the sample data.\n",
    "μ₀: The hypothesized population proportion under the null hypothesis, which is 0.5 (assuming no preference for tilting right or left).\n",
    "\n",
    "imulate the p-value\n",
    "To simulate a p-value:\n",
    "\n",
    "Model the Head Tilts: Assume that each couple’s head tilt is an independent coin flip with a 50% chance of tilting right.\n",
    "Run Simulations: Repeat this “coin-flipping” process for 124 couples, many times (e.g., 10,000 simulations).\n",
    "Calculate the Simulated Proportions: For each simulation, calculate the proportion of “right tilts.”\n",
    "Compare to Observed Value: Count how often the simulated proportion is at least as extreme as the observed value of 0.645.\n",
    "Determine the p-value: The p-value is the proportion of simulations where the simulated proportion is greater than or equal to 0.645.\n",
    "\n",
    "A small p-value would provide strong evidence against the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1495235",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "Smaller p-value cannot definitvely prove that the null hypothesis is false. It simply just means that the observed results are unlikely under the null hypothesis. Therefore, a p-value cannot prove Fido's innocence or guilt. If the p-value is low, it means that there is a strong evidence against Fido's innoce, and if the p-value is low, it means there is strong evidence for Fido's innocence. \n",
    "\n",
    "In short, in hypothesis testing, no p-value can definitvely prove either hypothesis. Instead, p-value helps determine if there is enough evience to reject the null hypothesis or fail to reject it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8365faa5",
   "metadata": {},
   "source": [
    "# Question 7 \n",
    "\n",
    "To modify the code for a **one-tailed** test instead of a **two-tailed** test and understand the differences, let’s explore the following:\n",
    "\n",
    "### 1. **Understanding One-Tailed vs. Two-Tailed Tests**:\n",
    "   - A **two-tailed test** checks for any significant difference in either direction. For example, if testing the effectiveness of a vaccine, a two-tailed test would look for both increases and decreases in effectiveness compared to the null hypothesis.\n",
    "   - A **one-tailed test** checks for a difference in one specific direction only. In the vaccine example, a one-tailed test might specifically test if the vaccine leads to an **increase in effectiveness** only (or just a decrease, depending on the hypothesis).\n",
    "\n",
    "### 2. **How to Adjust the Code for a One-Tailed Test**:\n",
    "   - In a **two-tailed test**, you typically calculate the p-value by checking the proportion of simulated results that are as extreme as the observed value in **both directions** (greater than and less than the observed value).\n",
    "   - In a **one-tailed test**, you only check in **one direction**. For instance, if you are interested in testing whether the proportion of improvements is **greater than** expected under the null hypothesis, you only need to calculate the p-value based on simulations that show a greater result than the observed statistic.\n",
    "\n",
    "   Here’s how you can adjust the code for a **one-tailed test**:\n",
    "\n",
    "   ```python\n",
    "   # Current observed proportion of improvement\n",
    "   observed_proportion = observed_improvement.mean()  # Assuming you have this variable already\n",
    "\n",
    "   # Simulate under H0 as before\n",
    "   np.random.seed(1)  # make simulation reproducible\n",
    "   number_of_simulations = 10000\n",
    "   IncreaseProportionSimulations_underH0random = np.zeros(number_of_simulations)\n",
    "\n",
    "   for i in range(number_of_simulations):\n",
    "       random_improvement = np.random.choice([0, 1], size=len(patient_data), replace=True)\n",
    "       IncreaseProportionSimulations_underH0random[i] = random_improvement.mean()\n",
    "\n",
    "   # Calculate the p-value for one-tailed test (greater than observed)\n",
    "   p_value_one_tailed = (IncreaseProportionSimulations_underH0random >= observed_proportion).mean()\n",
    "   ```\n",
    "\n",
    "   In this modified version, the code only calculates the p-value for results that are **greater than or equal to the observed proportion** (for a one-sided test). This makes it a **one-tailed test**.\n",
    "\n",
    "### 3. **How the Interpretation Changes**:\n",
    "   - In a **two-tailed test**, we interpret the p-value based on the likelihood of observing a result as extreme as the one observed in **either direction**. For example, we’re interested in both unusually high and unusually low outcomes.\n",
    "   - In a **one-tailed test**, the interpretation is directional: it only assesses the likelihood of observing a result as extreme as the one observed in **one specified direction** (e.g., only greater than or only less than).\n",
    "   - This directional approach makes the **one-tailed p-value smaller** compared to the two-tailed p-value, given the same observed result, because it is only considering one side of the distribution.\n",
    "\n",
    "### 4. **Why Expect a Smaller p-Value in a One-Tailed Test?**\n",
    "   - Since the one-tailed test focuses only on one end of the distribution, it naturally yields a smaller p-value compared to a two-tailed test with the same data. In other words, you’re dividing the “extreme” results by **one tail instead of two**, making it easier to reject the null hypothesis in a one-sided direction. \n",
    "   - This is why one-tailed tests have **more power** to detect an effect in a specific direction, but they should only be used if you have a clear reason to test in one direction and no interest in differences in the other direction.\n",
    "\n",
    "By adjusting the code in this way, you can perform a one-tailed test to see if the vaccine, for example, leads to a higher rate of improvement than expected under the null hypothesis, providing a more focused (and potentially more sensitive) test for a specific directional effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269b0dc",
   "metadata": {},
   "source": [
    "Here’s a detailed breakdown that includes all the specified requirements for the Fisher’s Tea Experiment with the STA130 students:\n",
    "\n",
    "---\n",
    "\n",
    "### Fisher's Tea Experiment - Analysis Report\n",
    "\n",
    "#### 1. Clarity of Documentation, Code, and Written Report\n",
    "The goal of this report is to evaluate whether STA130 students can correctly identify the order in which milk and tea are poured, beyond what would be expected by random guessing. The analysis follows standard hypothesis testing procedures, including the formulation of null and alternative hypotheses, calculation of test statistics, and interpretation of results.\n",
    "\n",
    "The code provided in the analysis calculates the observed proportion of correct responses, the standard error under the null hypothesis, the Z-score, and the corresponding p-value. This will help determine if the observed proportion is statistically significant.\n",
    "\n",
    "#### 2. Description of the Population and Sample, Parameter of Interest, and Observed Test Statistic\n",
    "- **Population**: The population of interest is all STA130 students who could potentially participate in a tea-tasting experiment.\n",
    "- **Sample**: The sample consists of 80 randomly selected STA130 students who each tasted one cup of tea and indicated whether they believed the milk or tea was poured first.\n",
    "- **Parameter of Interest**: The parameter of interest is the **proportion \\( p \\)** of all STA130 students who can correctly identify the pouring order. We’re testing whether this proportion differs from 0.5 (random guessing).\n",
    "- **Observed Test Statistic**: The observed proportion \\( \\hat{p} \\) of correct responses is calculated as follows:\n",
    "  \\[\n",
    "  \\hat{p} = \\frac{49 \\text{ correct responses}}{80 \\text{ total responses}} = 0.6125\n",
    "  \\]\n",
    "\n",
    "#### 3. Formal Null Hypothesis\n",
    "- **Formal Statement**: \n",
    "  - Null Hypothesis \\( (H_0) \\): The true proportion of STA130 students who can correctly identify the pouring order is equal to 0.5.\n",
    "  - \\( H_0: p = 0.5 \\)\n",
    "  \n",
    "- **Informal Interpretation**: Under the null hypothesis, we assume that STA130 students are just guessing, and any observed proportion close to 0.5 is due to random chance. This means that the students, on average, would have no ability to correctly identify the pouring order beyond a coin flip.\n",
    "\n",
    "#### 4. Alternative Hypothesis\n",
    "- **Formal Statement**:\n",
    "  - Alternative Hypothesis \\( (H_1) \\): The true proportion of STA130 students who can correctly identify the pouring order is greater than 0.5, suggesting an ability beyond random guessing.\n",
    "  - \\( H_1: p > 0.5 \\)\n",
    "  \n",
    "- **Informal Interpretation**: The alternative hypothesis suggests that students are not merely guessing; instead, they have some level of discernment that allows them to correctly identify the pouring order at a rate above 50%.\n",
    "\n",
    "#### 5. Quantitative Analysis\n",
    "The purpose of this quantitative analysis is to determine if the observed proportion of correct responses (0.6125) is significantly greater than the expected proportion under the null hypothesis (0.5). \n",
    "\n",
    "- **Step-by-Step Explanation**:\n",
    "  1. **Calculate the Observed Proportion**: The observed proportion \\( \\hat{p} = 0.6125 \\).\n",
    "  2. **Assume the Null Hypothesis**: Under \\( H_0 \\), we assume \\( p = 0.5 \\).\n",
    "  3. **Calculate the Standard Error**:\n",
    "     \\[\n",
    "     \\text{SE} = \\sqrt{\\frac{p(1 - p)}{n}} = \\sqrt{\\frac{0.5 \\times (1 - 0.5)}{80}} \\approx 0.0559\n",
    "     \\]\n",
    "  4. **Calculate the Z-Score**:\n",
    "     \\[\n",
    "     Z = \\frac{\\hat{p} - p}{\\text{SE}} = \\frac{0.6125 - 0.5}{0.0559} \\approx 2.01\n",
    "     \\]\n",
    "  5. **Calculate the p-value** for a one-tailed test:\n",
    "     ```python\n",
    "     import scipy.stats as stats\n",
    "\n",
    "     # Observed data\n",
    "     n = 80\n",
    "     observed_successes = 49\n",
    "     p_hat = observed_successes / n\n",
    "     p_null = 0.5\n",
    "     std_error = (p_null * (1 - p_null) / n) ** 0.5\n",
    "     z_score = (p_hat - p_null) / std_error\n",
    "     p_value = 1 - stats.norm.cdf(z_score)\n",
    "\n",
    "     print(\"Observed Proportion (p̂):\", p_hat)\n",
    "     print(\"Z-Score:\", z_score)\n",
    "     print(\"p-value:\", p_value)\n",
    "     ```\n",
    "  6. **Interpret the p-value**: The p-value represents the probability of observing a proportion as extreme as 0.6125 (or more extreme) under the null hypothesis that students are guessing. A p-value lower than a significance level (e.g., 0.05) would lead to rejecting \\( H_0 \\).\n",
    "\n",
    "#### 6. Explanation of the Method and Population Parameter\n",
    "This hypothesis test relies on calculating the Z-score, which standardizes the observed proportion under the null hypothesis, allowing us to compare it to a normal distribution. The one-tailed p-value provides insight into whether the observed result could plausibly be due to random guessing. The smaller the p-value, the stronger the evidence that the observed proportion differs from 0.5 in the direction suggested by the alternative hypothesis.\n",
    "\n",
    "#### 7. Findings and Conclusion\n",
    "- **Findings**: If the p-value is smaller than 0.05, we reject the null hypothesis, suggesting that the STA130 students may have a discernible ability to identify the pouring order of milk and tea. If the p-value is larger, we fail to reject the null hypothesis, indicating that the observed result could be due to chance.\n",
    "- **Conclusion**: Based on the observed p-value, we make a decision on \\( H_0 \\). If rejected, we conclude there’s evidence to suggest STA130 students are better than random guessing at identifying pouring order. If not rejected, we conclude that the data does not provide sufficient evidence to suggest any ability beyond guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455f629",
   "metadata": {},
   "source": [
    "# Question 9\n",
    "\n",
    "My skills for prompt eniginnering has improved each time I'm completed a task as I am now more skilled to ask chatbot the correct prompt for it to output the answers to my questions. Overall my skills has been evolving for the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef90870a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
